//! `TallyIO` Rate Limiting - Production-Ready Token Bucket Implementation
//!
//! Ultra-high-performance rate limiting with <10Î¼s latency guarantee.
//! Token bucket algorithm with burst protection for financial trading systems.
//!
//! ## Features
//! - **Token Bucket Algorithm**: Industry-standard rate limiting
//! - **Burst Protection**: Configurable burst capacity
//! - **Per-Client Limiting**: Individual limits per IP/client
//! - **Lock-free Operations**: Atomic operations for sub-microsecond performance
//! - **Adaptive Cleanup**: Automatic cleanup of expired entries
//! - **Zero-panic**: All operations return Results

use crate::error::{NetworkError, NetworkResult};
use crate::security::{RateLimitConfig, SecurityRequest, SecurityResult};
use dashmap::DashMap;
use std::net::IpAddr;
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::Notify;

/// Token bucket for rate limiting
#[derive(Debug)]
struct TokenBucket {
    /// Current number of tokens
    tokens: AtomicU64,
    /// Last refill timestamp (nanoseconds since epoch)
    last_refill: AtomicU64,
    /// Maximum capacity
    capacity: u32,
    /// Refill rate (tokens per second)
    refill_rate: u32,
}

impl TokenBucket {
    /// Create new token bucket
    #[must_use]
    fn new(capacity: u32, refill_rate: u32) -> Self {
        #[allow(clippy::cast_possible_truncation)] // Controlled truncation for nanosecond precision
        let now = Instant::now().elapsed().as_nanos() as u64;
        Self {
            tokens: AtomicU64::new(u64::from(capacity)),
            last_refill: AtomicU64::new(now),
            capacity,
            refill_rate,
        }
    }

    /// Try to consume tokens from bucket
    ///
    /// Returns true if tokens were successfully consumed
    #[inline]
    fn try_consume(&self, tokens_needed: u32) -> bool {
        #[allow(clippy::cast_possible_truncation)] // Controlled truncation for nanosecond precision
        let now = Instant::now().elapsed().as_nanos() as u64;
        let tokens_needed_u64 = u64::from(tokens_needed);

        // Refill tokens based on elapsed time
        self.refill_tokens(now);

        // Try to consume tokens atomically
        let current_tokens = self.tokens.load(Ordering::Relaxed);
        if current_tokens >= tokens_needed_u64 {
            // Use compare_exchange to ensure atomicity
            if self.tokens.compare_exchange_weak(
                current_tokens,
                current_tokens - tokens_needed_u64,
                Ordering::Relaxed,
                Ordering::Relaxed,
            ).is_ok() {
                true
            } else {
                // Retry once if CAS failed due to concurrent modification
                let retry_tokens = self.tokens.load(Ordering::Relaxed);
                if retry_tokens >= tokens_needed_u64 {
                    self.tokens
                        .compare_exchange_weak(
                            retry_tokens,
                            retry_tokens - tokens_needed_u64,
                            Ordering::Relaxed,
                            Ordering::Relaxed,
                        )
                        .is_ok()
                } else {
                    false
                }
            }
        } else {
            false
        }
    }

    /// Refill tokens based on elapsed time
    #[inline]
    fn refill_tokens(&self, now: u64) {
        let last_refill = self.last_refill.load(Ordering::Relaxed);
        let elapsed_ns = now.saturating_sub(last_refill);
        
        if elapsed_ns > 0 {
            // Calculate tokens to add (nanoseconds to seconds conversion)
            #[allow(clippy::cast_precision_loss)] // Acceptable for time calculations
            let elapsed_seconds = elapsed_ns as f64 / 1_000_000_000.0_f64;
            #[allow(clippy::cast_possible_truncation, clippy::cast_sign_loss)] // Controlled conversion for token calculation
            let tokens_to_add = (elapsed_seconds * f64::from(self.refill_rate)) as u64;
            
            if tokens_to_add > 0 {
                // Update last refill time
                if self.last_refill.compare_exchange_weak(
                    last_refill,
                    now,
                    Ordering::Relaxed,
                    Ordering::Relaxed,
                ).is_ok() {
                    // Add tokens up to capacity
                    let current_tokens = self.tokens.load(Ordering::Relaxed);
                    let max_tokens = u64::from(self.capacity);
                    let new_tokens = (current_tokens + tokens_to_add).min(max_tokens);
                    
                    self.tokens.store(new_tokens, Ordering::Relaxed);
                }
            }
        }
    }

    /// Get current token count
    #[must_use]
    fn current_tokens(&self) -> u32 {
        #[allow(clippy::cast_possible_truncation)] // Controlled truncation for nanosecond precision
        let now_nanos = Instant::now().elapsed().as_nanos() as u64;
        self.refill_tokens(now_nanos);
        #[allow(clippy::cast_possible_truncation)] // Token count fits in u32
        let current_tokens = self.tokens.load(Ordering::Relaxed) as u32;
        current_tokens
    }

    /// Get time until next token is available
    #[must_use]
    fn time_until_available(&self) -> Duration {
        let current_tokens = self.current_tokens();
        if current_tokens > 0 {
            Duration::ZERO
        } else {
            // Calculate time for one token to be refilled
            Duration::from_secs_f64(1.0 / f64::from(self.refill_rate))
        }
    }
}

/// Rate limiter statistics
#[derive(Debug, Clone, Default)]
pub struct RateLimiterStats {
    /// Total requests processed
    pub total_requests: u64,
    /// Requests allowed
    pub allowed_requests: u64,
    /// Requests rate limited
    pub rate_limited_requests: u64,
    /// Active clients being tracked
    pub active_clients: u64,
    /// Average processing time (microseconds)
    pub avg_processing_time_us: u64,
}

/// Production-ready rate limiter
#[derive(Clone)]
pub struct RateLimiter {
    /// Token buckets per client IP
    buckets: Arc<DashMap<IpAddr, Arc<TokenBucket>>>,
    /// Configuration
    config: RateLimitConfig,
    /// Statistics
    stats: Arc<parking_lot::RwLock<RateLimiterStats>>,
    /// Cleanup task shutdown signal
    cleanup_shutdown: Arc<Notify>,
    /// Cleanup task handle
    cleanup_handle: Arc<parking_lot::Mutex<Option<tokio::task::JoinHandle<()>>>>,
}

impl RateLimiter {
    /// Create new rate limiter
    ///
    /// # Errors
    /// Returns error if configuration is invalid
    pub fn new(config: RateLimitConfig) -> NetworkResult<Self> {
        // Validate configuration
        if config.max_requests_per_second == 0 {
            return Err(NetworkError::config(
                "max_requests_per_second",
                "Must be greater than 0",
            ));
        }

        if config.burst_capacity < config.max_requests_per_second {
            return Err(NetworkError::config(
                "burst_capacity",
                "Must be >= max_requests_per_second",
            ));
        }

        let rate_limiter = Self {
            buckets: Arc::new(DashMap::new()),
            config,
            stats: Arc::new(parking_lot::RwLock::new(RateLimiterStats::default())),
            cleanup_shutdown: Arc::new(Notify::new()),
            cleanup_handle: Arc::new(parking_lot::Mutex::new(None)),
        };

        // Start cleanup task
        rate_limiter.start_cleanup_task();

        Ok(rate_limiter)
    }

    /// Check if request should be rate limited
    ///
    /// # Errors
    /// Returns error if rate limiting check fails
    pub fn check_request(&self, request: &SecurityRequest) -> NetworkResult<SecurityResult> {
        let start_time = Instant::now();

        // Get or create token bucket for client IP
        let bucket = self.get_or_create_bucket(request.client_ip);

        // Try to consume one token
        let allowed = bucket.try_consume(1);

        // Update statistics
        self.update_stats(start_time, allowed);

        if allowed {
            Ok(SecurityResult::Allow)
        } else {
            // Calculate retry-after time
            let retry_after = bucket.time_until_available();
            Ok(SecurityResult::RateLimit { retry_after })
        }
    }

    /// Get or create token bucket for IP
    fn get_or_create_bucket(&self, ip: IpAddr) -> Arc<TokenBucket> {
        self.buckets
            .entry(ip)
            .or_insert_with(|| {
                Arc::new(TokenBucket::new(
                    self.config.burst_capacity,
                    self.config.refill_rate,
                ))
            })
            .clone()
    }

    /// Update rate limiter statistics
    fn update_stats(&self, start_time: Instant, allowed: bool) {
        let elapsed = start_time.elapsed();
        let mut stats = self.stats.write();

        stats.total_requests += 1;
        if allowed {
            stats.allowed_requests += 1;
        } else {
            stats.rate_limited_requests += 1;
        }

        stats.active_clients = self.buckets.len() as u64;

        // Update average processing time (exponential moving average)
        #[allow(clippy::cast_possible_truncation)] // Acceptable for metrics
        let elapsed_us = elapsed.as_micros() as u64;
        if stats.avg_processing_time_us == 0 {
            stats.avg_processing_time_us = elapsed_us;
        } else {
            stats.avg_processing_time_us = 
                (stats.avg_processing_time_us * 9 + elapsed_us) / 10;
        }
    }

    /// Start cleanup task for expired buckets
    fn start_cleanup_task(&self) {
        let buckets = self.buckets.clone();
        let cleanup_interval = self.config.cleanup_interval;
        let shutdown_signal = self.cleanup_shutdown.clone();

        let handle = tokio::spawn(async move {
            let mut interval = tokio::time::interval(cleanup_interval);

            loop {
                tokio::select! {
                    _ = interval.tick() => {
                        Self::cleanup_expired_buckets(&buckets);
                    }
                    () = shutdown_signal.notified() => {
                        break;
                    }
                }
            }
        });

        *self.cleanup_handle.lock() = Some(handle);
    }

    /// Cleanup expired token buckets
    fn cleanup_expired_buckets(buckets: &DashMap<IpAddr, Arc<TokenBucket>>) {
        #[allow(clippy::cast_possible_truncation)] // Controlled truncation for nanosecond precision
        let now = Instant::now().elapsed().as_nanos() as u64;
        #[allow(clippy::cast_possible_truncation)] // Controlled truncation for nanosecond precision
        let expiry_threshold = Duration::from_secs(3600).as_nanos() as u64; // 1 hour

        buckets.retain(|_, bucket| {
            let last_refill = bucket.last_refill.load(Ordering::Relaxed);
            now.saturating_sub(last_refill) < expiry_threshold
        });
    }

    /// Get current statistics
    #[must_use]
    pub fn stats(&self) -> RateLimiterStats {
        let mut stats = self.stats.read().clone();
        stats.active_clients = self.buckets.len() as u64;
        stats
    }

    /// Check if rate limiter is healthy
    #[must_use]
    pub fn is_healthy(&self) -> bool {
        let stats = self.stats.read();
        
        // Healthy if processing time is under 50Î¼s and success rate > 95%
        #[allow(clippy::cast_precision_loss)] // Acceptable for success rate calculation
        let success_rate = if stats.total_requests > 0 {
            stats.allowed_requests as f64 / stats.total_requests as f64
        } else {
            1.0_f64
        };

        stats.avg_processing_time_us < 50 && success_rate > 0.95
    }

    /// Shutdown rate limiter
    pub async fn shutdown(&self) {
        self.cleanup_shutdown.notify_one();

        let handle = self.cleanup_handle.lock().take();
        if let Some(handle) = handle {
            let _ = handle.await;
        }
    }
}

impl Drop for RateLimiter {
    fn drop(&mut self) {
        self.cleanup_shutdown.notify_one();
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::net::Ipv4Addr;

    fn create_test_config() -> RateLimitConfig {
        RateLimitConfig {
            max_requests_per_second: 10,
            burst_capacity: 20,
            refill_rate: 10,
            cleanup_interval: Duration::from_secs(60),
        }
    }

    fn create_test_request(ip: IpAddr) -> SecurityRequest {
        SecurityRequest {
            client_ip: ip,
            method: "GET".to_string(),
            path: "/api/test".to_string(),
            headers: std::collections::HashMap::new(),
            body: Vec::new(),
            certificate_chain: None,
            timestamp: std::time::SystemTime::now(),
            user_agent: Some("test-client".to_string()),
        }
    }

    #[tokio::test]
    async fn test_rate_limiter_creation() -> NetworkResult<()> {
        let config = create_test_config();
        let rate_limiter = RateLimiter::new(config)?;
        
        assert!(rate_limiter.is_healthy());
        
        rate_limiter.shutdown().await;
        Ok(())
    }

    #[tokio::test]
    async fn test_token_bucket_basic() {
        let bucket = TokenBucket::new(10, 5);
        
        // Should have full capacity initially
        assert_eq!(bucket.current_tokens(), 10);
        
        // Should be able to consume tokens
        assert!(bucket.try_consume(5));
        assert_eq!(bucket.current_tokens(), 5);
        
        // Should not be able to consume more than available
        assert!(!bucket.try_consume(10));
        assert_eq!(bucket.current_tokens(), 5);
    }

    #[tokio::test]
    async fn test_rate_limiting_allows_within_limit() -> NetworkResult<()> {
        let config = create_test_config();
        let rate_limiter = RateLimiter::new(config)?;
        
        let ip = IpAddr::V4(Ipv4Addr::new(192, 168, 1, 1));
        let request = create_test_request(ip);
        
        // First few requests should be allowed
        for _ in 0_i32..10_i32 {
            let result = rate_limiter.check_request(&request)?;
            assert!(matches!(result, SecurityResult::Allow));
        }
        
        rate_limiter.shutdown().await;
        Ok(())
    }

    #[tokio::test]
    async fn test_rate_limiting_blocks_over_limit() -> NetworkResult<()> {
        let config = RateLimitConfig {
            max_requests_per_second: 2,
            burst_capacity: 5,
            refill_rate: 2,
            cleanup_interval: Duration::from_secs(60),
        };
        let rate_limiter = RateLimiter::new(config)?;
        
        let ip = IpAddr::V4(Ipv4Addr::new(192, 168, 1, 2));
        let request = create_test_request(ip);
        
        // Consume all tokens
        for _ in 0_i32..5_i32 {
            let result = rate_limiter.check_request(&request)?;
            assert!(matches!(result, SecurityResult::Allow));
        }

        // Next request should be rate limited
        let result = rate_limiter.check_request(&request)?;
        assert!(matches!(result, SecurityResult::RateLimit { .. }));
        
        rate_limiter.shutdown().await;
        Ok(())
    }

    #[tokio::test]
    async fn test_different_ips_independent_limits() -> NetworkResult<()> {
        let config = create_test_config();
        let rate_limiter = RateLimiter::new(config)?;
        
        let ip1 = IpAddr::V4(Ipv4Addr::new(192, 168, 1, 1));
        let ip2 = IpAddr::V4(Ipv4Addr::new(192, 168, 1, 2));
        
        let request1 = create_test_request(ip1);
        let request2 = create_test_request(ip2);
        
        // Both IPs should have independent limits
        for _ in 0_i32..10_i32 {
            let result1 = rate_limiter.check_request(&request1)?;
            let result2 = rate_limiter.check_request(&request2)?;
            
            assert!(matches!(result1, SecurityResult::Allow));
            assert!(matches!(result2, SecurityResult::Allow));
        }
        
        rate_limiter.shutdown().await;
        Ok(())
    }

    #[tokio::test]
    async fn test_performance_requirement() -> NetworkResult<()> {
        let config = create_test_config();
        let rate_limiter = RateLimiter::new(config)?;
        
        let ip = IpAddr::V4(Ipv4Addr::new(192, 168, 1, 1));
        let request = create_test_request(ip);
        
        // Test performance - should be under 50Î¼s
        let start = Instant::now();
        let _result = rate_limiter.check_request(&request)?;
        let elapsed = start.elapsed();
        
        assert!(elapsed.as_micros() < 50, "Rate limiting took {}Î¼s (target: <50Î¼s)", elapsed.as_micros());
        
        rate_limiter.shutdown().await;
        Ok(())
    }
}
